# AI Assistant Implementation Plan
**Project Name:** Jarvis AI Assistant  
**Date:** December 27, 2025  
**Version:** 1.0

---

## Executive Summary

This document outlines a comprehensive plan to build an intelligent AI assistant using Swift6/SwiftUI for the frontend, LangGraph for orchestration, FastAPI for backend services, and GPT-5-nano as the core reasoning engine. The system will support multi-modal file processing, RAG-based memory, internet search, and streaming responses with visible reasoning.

---

## 1. Architecture Overview

### 1.1 High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Swift6/SwiftUI Frontend                   â”‚
â”‚  - Modern UI with reasoning dropdown                         â”‚
â”‚  - Streaming response display                                â”‚
â”‚  - File upload interface                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚ HTTP/WebSocket
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   FastAPI Backend Server                     â”‚
â”‚  - REST API endpoints                                        â”‚
â”‚  - WebSocket for streaming                                   â”‚
â”‚  - File handling & validation                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                LangGraph Orchestrator                        â”‚
â”‚  - Agent workflow management                                 â”‚
â”‚  - Tool routing & coordination                               â”‚
â”‚  - State management                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚           â”‚           â”‚              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚ GPT-5-nano â”‚ â”‚ ChromaDBâ”‚ â”‚  File   â”‚ â”‚ DuckDuckGo â”‚
â”‚   (OpenAI) â”‚ â”‚   RAG   â”‚ â”‚ Processorâ”‚ â”‚   Search   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 Component Details

#### **Frontend: Swift6/SwiftUI (macOS/iOS)**
- Native macOS application
- Modern, responsive UI with smooth animations
- Real-time streaming text display
- Collapsible reasoning panel
- File drag-and-drop support
- Conversation history view

#### **Backend: FastAPI**
- Python 3.11+ for optimal performance
- Async/await for concurrent operations
- Server-Sent Events (SSE) for response streaming
- File upload handling with size limits
- CORS configuration for local development
- Health check endpoints

#### **Orchestrator: LangGraph**
- State machine for agent workflows
- Tool selection logic
- Memory management
- Error recovery mechanisms
- Parallel tool execution when applicable

#### **Core LLM: GPT-5-nano**
- Function calling capabilities
- Streaming support
- Reasoning trace extraction
- Context window: ~128K tokens
- Fast inference for nano variant

#### **RAG System: ChromaDB**
- Local vector database
- Persistent storage
- Metadata filtering
- Semantic search
- Automatic embedding generation

---

## 2. Critical Analysis & Gap Identification

### 2.1 Feasibility Assessment

âœ… **Fully Feasible:**
- GPT-5-nano is available via OpenAI API (released Aug 2025)
- LangGraph 1.0.5 is production-ready
- ChromaDB supports local deployment
- Swift 6 has excellent HTTP/WebSocket support
- FastAPI supports SSE streaming

âš ï¸ **Requires Attention:**
1. **GPT-5-nano Reasoning Display**: GPT-5 series has reasoning capabilities, but reasoning tokens need special handling
2. **File Processing Complexity**: Multiple file formats require different parsers
3. **Cost Management**: OpenAI API costs for streaming + reasoning
4. **Latency**: Multiple hops (Swift â†’ FastAPI â†’ LangGraph â†’ OpenAI)
5. **State Synchronization**: Keeping ChromaDB and conversation state in sync

### 2.2 Identified Gaps & Solutions

| Gap | Impact | Solution |
|-----|--------|----------|
| **Reasoning extraction from GPT-5-nano** | High | Use `include_reasoning=true` parameter in API calls; parse reasoning items separately from response |
| **Multi-format file parsing** | High | Implement modular parser system with fallback mechanisms |
| **Streaming with tool calls** | Medium | Implement buffering strategy; show "thinking" state during tool execution |
| **Local vs cloud ChromaDB** | Medium | Start with local SQLite backend, plan migration path to ClickHouse for scale |
| **Error handling in streams** | Medium | Implement SSE error events and UI error states |
| **API cost control** | Medium | Implement token counting, rate limiting, and cost tracking |
| **Swift-Python communication** | Low | Use standard HTTP/WebSocket protocols |

---

## 3. Technical Stack Details

### 3.1 Frontend Stack

```swift
// Key Dependencies
- Swift 6.0+
- SwiftUI 5.0+
- Foundation (URLSession for networking)
- Combine (reactive programming)
- MarkdownUI (for rendering formatted responses)
```

**Libraries:**
- `SwiftUIIntrospect` - for advanced UI customization
- `MarkdownUI` - markdown rendering
- `Lottie-iOS` - loading animations
- `EventSource` or custom SSE client

### 3.2 Backend Stack

```python
# Core Dependencies
fastapi==0.115.0
uvicorn[standard]==0.32.0
python-multipart==0.0.18  # file uploads
sse-starlette==2.2.0      # server-sent events
```

**Additional Libraries:**
```python
# LLM & Orchestration
langgraph==1.0.5
langchain==0.3.12
openai==1.58.0

# RAG & Embeddings
chromadb==0.5.23
sentence-transformers==3.3.1  # local embeddings option

# File Processing
pypdf==5.1.0                  # PDF (fast, reliable)
python-docx==1.1.2            # Word documents
Pillow==11.0.0                # Images
python-magic==0.4.27          # file type detection
markdown==3.7                 # Markdown
chardet==5.2.0                # encoding detection
pytesseract==0.3.13           # OCR for images (optional)
pymupdf==1.25.1               # Advanced PDF with images

# Search
duckduckgo-search==7.0.0

# Utilities
pydantic==2.10.4
python-dotenv==1.0.1
tenacity==9.0.0               # retries
```

### 3.3 Development Tools

- **Version Control**: Git
- **API Testing**: Bruno/Postman
- **Python Environment**: venv or poetry
- **Xcode**: 15.0+ for Swift development
- **Database Tools**: ChromaDB admin UI or custom dashboard

---

## 4. Detailed Component Design

### 4.1 File Processing System

#### **Architecture**

```python
class FileProcessor:
    """Base class for file processors"""
    
class PDFProcessor(FileProcessor):
    """Handles PDF extraction with fallback strategies"""
    # Primary: pypdf
    # Fallback: pymupdf
    # OCR: pytesseract for scanned PDFs
    
class ImageProcessor(FileProcessor):
    """Processes images with vision + OCR"""
    # GPT-5-nano vision for understanding
    # pytesseract for text extraction
    
class DocumentProcessor(FileProcessor):
    """Handles Word, Markdown, text files"""
    # python-docx for .docx
    # direct read for .txt, .md, .py
    
class FileProcessorFactory:
    """Routes files to appropriate processor"""
```

#### **Supported Formats & Strategy**

| Format | Library | Strategy |
|--------|---------|----------|
| PDF | pypdf â†’ pymupdf | Text extraction, then OCR if needed |
| Images (jpg, png) | Pillow + GPT-5 Vision | Vision API + OCR fallback |
| Word (.docx) | python-docx | Extract text, tables, images |
| Markdown (.md) | built-in | Direct read with frontmatter parsing |
| Python (.py) | built-in | Code parsing with AST analysis |
| Text (.txt) | built-in | Encoding-aware read (chardet) |
| Code files | built-in | Syntax highlighting metadata |

#### **Processing Pipeline**

```
1. File Upload â†’ FastAPI endpoint
2. Validation (size, type, security)
3. File type detection (python-magic)
4. Route to appropriate processor
5. Extract text + metadata + images
6. Chunk content (for long documents)
7. Generate embeddings
8. Store in ChromaDB
9. Return processing status + preview
```

### 4.2 LangGraph Agent Design

#### **State Schema**

```python
from typing import TypedDict, Annotated, Sequence
from langchain_core.messages import BaseMessage

class AgentState(TypedDict):
    messages: Annotated[Sequence[BaseMessage], "conversation history"]
    reasoning: Annotated[list[str], "reasoning traces"]
    tool_calls: Annotated[list[dict], "pending tool calls"]
    file_context: Annotated[dict, "uploaded file references"]
    rag_results: Annotated[list[dict], "retrieved documents"]
    search_results: Annotated[list[dict], "web search results"]
    next_action: Annotated[str, "routing decision"]
```

#### **Agent Graph Structure**

```
START
  â†“
[User Input Node]
  â†“
[Intent Classification]
  â†“
[Decision Router]
  â†“
  â”œâ†’ [File Processing Tool]
  â”œâ†’ [RAG Retrieval Tool]
  â”œâ†’ [Web Search Tool]
  â”œâ†’ [Direct Response]
  â†“
[Tool Execution (Parallel if applicable)]
  â†“
[Response Generation with GPT-5-nano]
  â†“
[Reasoning Extraction]
  â†“
[Stream to User]
  â†“
END
```

#### **Tools Definition**

```python
tools = [
    {
        "type": "function",
        "function": {
            "name": "search_knowledge_base",
            "description": "Search stored documents using semantic similarity",
            "parameters": {
                "query": "string",
                "top_k": "integer",
                "filter": "object"
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "web_search",
            "description": "Search the internet using DuckDuckGo",
            "parameters": {
                "query": "string",
                "max_results": "integer"
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "process_uploaded_file",
            "description": "Extract and analyze content from uploaded file",
            "parameters": {
                "file_id": "string",
                "extract_images": "boolean"
            }
        }
    }
]
```

### 4.3 RAG Implementation

#### **ChromaDB Configuration**

```python
import chromadb
from chromadb.config import Settings

client = chromadb.PersistentClient(
    path="/path/to/jarvis/chroma_db",
    settings=Settings(
        anonymized_telemetry=False,
        allow_reset=True
    )
)

collection = client.get_or_create_collection(
    name="jarvis_knowledge",
    metadata={
        "hnsw:space": "cosine",
        "hnsw:construction_ef": 100,
        "hnsw:M": 16
    },
    embedding_function=None  # Use OpenAI embeddings
)
```

#### **Embedding Strategy**

**Option 1: OpenAI Embeddings** (Recommended)
- Model: `text-embedding-3-small` or `text-embedding-3-large`
- Dimension: 1536 (small) or 3072 (large)
- Cost: ~$0.02/$0.13 per 1M tokens
- Pros: High quality, consistent with GPT-5

**Option 2: Local Embeddings** (Cost-saving)
- Model: `all-MiniLM-L6-v2` or `bge-small-en-v1.5`
- Dimension: 384 or 768
- Cost: Free (local compute)
- Pros: No API costs, privacy

**Recommendation**: Start with OpenAI for best quality, add local option later

#### **Chunking Strategy**

```python
from langchain.text_splitter import RecursiveCharacterTextSplitter

splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200,
    separators=["\n\n", "\n", ". ", " ", ""],
    length_function=len
)
```

#### **Retrieval Pipeline**

```python
async def retrieve_context(query: str, top_k: int = 5):
    # 1. Generate query embedding
    embedding = await get_embedding(query)
    
    # 2. Search ChromaDB
    results = collection.query(
        query_embeddings=[embedding],
        n_results=top_k,
        include=["documents", "metadatas", "distances"]
    )
    
    # 3. Re-rank (optional, using cross-encoder)
    # 4. Format for LLM context
    return format_results(results)
```

### 4.4 Streaming Implementation

#### **Backend: FastAPI SSE**

```python
from sse_starlette.sse import EventSourceResponse
from fastapi import FastAPI
import asyncio

app = FastAPI()

@app.post("/chat/stream")
async def chat_stream(request: ChatRequest):
    async def event_generator():
        try:
            # Initialize LangGraph agent
            agent = create_agent()
            
            # Stream from OpenAI
            async for chunk in agent.astream(request.messages):
                # Separate reasoning from response
                if "reasoning" in chunk:
                    yield {
                        "event": "reasoning",
                        "data": json.dumps(chunk["reasoning"])
                    }
                
                if "content" in chunk:
                    yield {
                        "event": "content",
                        "data": json.dumps(chunk["content"])
                    }
                
                if "tool_calls" in chunk:
                    yield {
                        "event": "tool",
                        "data": json.dumps(chunk["tool_calls"])
                    }
            
            yield {"event": "done", "data": ""}
            
        except Exception as e:
            yield {
                "event": "error",
                "data": json.dumps({"error": str(e)})
            }
    
    return EventSourceResponse(event_generator())
```

#### **Frontend: Swift SSE Client**

```swift
import Foundation

class StreamingChatService: ObservableObject {
    @Published var currentMessage: String = ""
    @Published var reasoning: [String] = []
    @Published var isStreaming: Bool = false
    
    func sendMessage(_ message: String) async {
        isStreaming = true
        currentMessage = ""
        reasoning = []
        
        guard let url = URL(string: "http://localhost:8000/chat/stream") else { return }
        
        var request = URLRequest(url: url)
        request.httpMethod = "POST"
        request.setValue("application/json", forHTTPHeaderField: "Content-Type")
        
        let body = ["message": message]
        request.httpBody = try? JSONEncoder().encode(body)
        
        do {
            let (bytes, _) = try await URLSession.shared.bytes(for: request)
            
            for try await line in bytes.lines {
                if line.hasPrefix("data: ") {
                    let data = String(line.dropFirst(6))
                    await handleStreamEvent(data)
                }
            }
        } catch {
            print("Streaming error: \(error)")
        }
        
        isStreaming = false
    }
    
    @MainActor
    func handleStreamEvent(_ data: String) {
        guard let eventData = data.data(using: .utf8),
              let json = try? JSONSerialization.jsonObject(with: eventData) as? [String: Any] else {
            return
        }
        
        if let content = json["content"] as? String {
            currentMessage += content
        } else if let reasoningText = json["reasoning"] as? String {
            reasoning.append(reasoningText)
        }
    }
}
```

### 4.5 UI Design Specifications

#### **Main Chat Interface**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Jarvis AI Assistant                          [âš™ï¸] [ğŸ“] â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  User: How does quantum computing work?                 â”‚
â”‚                                                          â”‚
â”‚  Assistant: [Streaming response...]                     â”‚
â”‚  â–¼ Show Reasoning (2 steps)                            â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚    â”‚ 1. Breaking down quantum computing concepts â”‚     â”‚
â”‚    â”‚ 2. Structuring explanation for clarity      â”‚     â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                          â”‚
â”‚  [ğŸ“ Drag file here or click to upload]                â”‚
â”‚                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Type your message...                    [â†‘ Send]      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### **SwiftUI Component Structure**

```swift
struct ContentView: View {
    @StateObject private var chatService = StreamingChatService()
    @State private var inputText = ""
    @State private var showReasoning = false
    
    var body: some View {
        VStack(spacing: 0) {
            // Header
            HeaderView()
            
            // Message List
            ScrollView {
                LazyVStack(alignment: .leading, spacing: 16) {
                    ForEach(chatService.messages) { message in
                        MessageBubbleView(message: message)
                        
                        if message.hasReasoning {
                            ReasoningDropdownView(
                                reasoning: message.reasoning,
                                isExpanded: $showReasoning
                            )
                        }
                    }
                }
                .padding()
            }
            
            // File Upload Area
            FileDropZone()
            
            // Input Bar
            ChatInputBar(
                text: $inputText,
                onSend: { chatService.sendMessage(inputText) }
            )
        }
    }
}

struct ReasoningDropdownView: View {
    let reasoning: [String]
    @Binding var isExpanded: Bool
    
    var body: some View {
        VStack(alignment: .leading, spacing: 8) {
            Button(action: { isExpanded.toggle() }) {
                HStack {
                    Image(systemName: isExpanded ? "chevron.down" : "chevron.right")
                    Text("Reasoning (\(reasoning.count) steps)")
                        .font(.caption)
                        .foregroundColor(.secondary)
                }
            }
            
            if isExpanded {
                VStack(alignment: .leading, spacing: 4) {
                    ForEach(reasoning.indices, id: \.self) { index in
                        HStack(alignment: .top) {
                            Text("\(index + 1).")
                                .font(.caption2)
                                .foregroundColor(.secondary)
                            Text(reasoning[index])
                                .font(.caption)
                                .foregroundColor(.secondary)
                        }
                    }
                }
                .padding(.leading, 20)
                .padding(.vertical, 8)
                .background(Color.gray.opacity(0.1))
                .cornerRadius(8)
            }
        }
    }
}
```

---

## 5. Implementation Roadmap

### Phase 1: Foundation (Weeks 1-2)

**Backend Setup**
- [ ] Initialize FastAPI project structure
- [ ] Set up Python virtual environment
- [ ] Configure environment variables (.env)
- [ ] Implement basic health check endpoints
- [ ] Set up OpenAI API client
- [ ] Configure CORS for local development

**Frontend Setup**
- [ ] Create Swift/SwiftUI Xcode project
- [ ] Set up project structure (MVVM)
- [ ] Implement basic UI layout
- [ ] Create networking layer with URLSession
- [ ] Add environment configuration

**Deliverables:**
- Running FastAPI server with health check
- Swift app that can connect to local server
- Basic request/response flow working

### Phase 2: Core Chat Functionality (Weeks 3-4)

**Backend**
- [ ] Implement GPT-5-nano integration
- [ ] Add streaming support with SSE
- [ ] Create chat endpoint
- [ ] Implement conversation state management
- [ ] Add error handling and retries

**Frontend**
- [ ] Build chat message UI
- [ ] Implement SSE client
- [ ] Add streaming text display
- [ ] Create message history view
- [ ] Add loading states and animations

**Testing**
- [ ] Test basic chat flow
- [ ] Test streaming performance
- [ ] Test error scenarios

**Deliverables:**
- Working chat interface with streaming responses
- Conversation persistence
- Error handling

### Phase 3: LangGraph Integration (Weeks 5-6)

**LangGraph Setup**
- [ ] Define agent state schema
- [ ] Create agent graph structure
- [ ] Implement routing logic
- [ ] Add tool definitions
- [ ] Set up state persistence

**Testing**
- [ ] Test agent decision making
- [ ] Test state transitions
- [ ] Test error recovery

**Deliverables:**
- LangGraph orchestrator managing chat flow
- Basic tool routing working

### Phase 4: File Processing (Weeks 7-8)

**Backend**
- [ ] Implement file upload endpoint
- [ ] Create file processor factory
- [ ] Implement PDF processor
- [ ] Implement image processor (with vision)
- [ ] Implement document processor (.docx, .md, .py, .txt)
- [ ] Add file validation and security checks
- [ ] Implement chunking strategy

**Frontend**
- [ ] Create file upload UI
- [ ] Add drag-and-drop support
- [ ] Show upload progress
- [ ] Display file processing status
- [ ] Add file preview

**Testing**
- [ ] Test each file type
- [ ] Test large files
- [ ] Test error cases (corrupted files)

**Deliverables:**
- Multi-format file processing working
- File upload UI integrated

### Phase 5: RAG System (Weeks 9-10)

**ChromaDB Setup**
- [ ] Initialize ChromaDB locally
- [ ] Create collection schema
- [ ] Implement embedding generation
- [ ] Create indexing pipeline
- [ ] Build retrieval functions

**Integration**
- [ ] Add RAG tool to LangGraph
- [ ] Implement context injection
- [ ] Add metadata filtering
- [ ] Create search UI (optional)

**Testing**
- [ ] Test semantic search quality
- [ ] Test retrieval speed
- [ ] Test with various document types

**Deliverables:**
- Working RAG system
- Documents searchable by AI
- Context-aware responses

### Phase 6: Internet Search (Week 11)

**Backend**
- [ ] Integrate DuckDuckGo search API
- [ ] Create search tool
- [ ] Add result parsing and formatting
- [ ] Implement caching (optional)

**LangGraph**
- [ ] Add search tool to agent
- [ ] Implement search decision logic
- [ ] Handle search results in context

**Testing**
- [ ] Test search accuracy
- [ ] Test rate limiting
- [ ] Test with various queries

**Deliverables:**
- Internet search capability
- AI can search web when needed

### Phase 7: Reasoning Display (Week 12)

**Backend**
- [ ] Extract reasoning from GPT-5 responses
- [ ] Structure reasoning data
- [ ] Stream reasoning separately

**Frontend**
- [ ] Create reasoning dropdown component
- [ ] Add expand/collapse animation
- [ ] Style reasoning display
- [ ] Add reasoning to message model

**Testing**
- [ ] Test reasoning extraction
- [ ] Test UI interactions

**Deliverables:**
- Visible AI reasoning in UI
- Smooth UX for reasoning display

### Phase 8: Optimization & Polish (Weeks 13-14)

**Performance**
- [ ] Optimize database queries
- [ ] Add caching where appropriate
- [ ] Optimize chunking parameters
- [ ] Profile and optimize hot paths
- [ ] Reduce API calls where possible

**UI/UX**
- [ ] Polish animations
- [ ] Add keyboard shortcuts
- [ ] Improve error messages
- [ ] Add dark mode
- [ ] Accessibility improvements

**Cost Optimization**
- [ ] Implement token counting
- [ ] Add cost tracking
- [ ] Optimize prompt lengths
- [ ] Consider caching strategies

**Testing**
- [ ] End-to-end testing
- [ ] Performance testing
- [ ] User acceptance testing

**Deliverables:**
- Optimized, production-ready system
- Polished UI
- Cost controls in place

### Phase 9: Documentation & Deployment (Week 15)

**Documentation**
- [ ] API documentation
- [ ] User guide
- [ ] Developer setup guide
- [ ] Architecture documentation

**Deployment**
- [ ] Create deployment scripts
- [ ] Set up logging and monitoring
- [ ] Create backup strategy
- [ ] Write deployment guide

**Deliverables:**
- Complete documentation
- Deployment-ready application

---

## 6. Cost Analysis

### 6.1 API Costs (Monthly Estimates)

**OpenAI GPT-5-nano** (as of Dec 2025)
- Input: ~$0.10 / 1M tokens
- Output: ~$0.30 / 1M tokens
- Reasoning: Additional cost for reasoning tokens

**Assumptions:**
- 1000 messages/month
- Average 500 input tokens/message
- Average 300 output tokens/message
- 50% of messages use reasoning (+200 tokens)

**Calculation:**
```
Input: 1000 * 500 * $0.10/1M = $0.05
Output: 1000 * 300 * $0.30/1M = $0.09
Reasoning: 500 * 200 * $0.30/1M = $0.03
Total: ~$0.17/month (light usage)
```

**Moderate usage (10K messages/month): ~$1.70/month**
**Heavy usage (100K messages/month): ~$17/month**

**Embeddings (text-embedding-3-small)**
- $0.02 / 1M tokens
- 1000 documents, avg 1000 tokens each
- Cost: $0.02 (one-time per document)

**Total Monthly Cost (moderate usage): ~$5-10/month**

### 6.2 Infrastructure Costs

- **ChromaDB**: Free (local deployment)
- **FastAPI**: Free (self-hosted)
- **DuckDuckGo**: Free
- **Development Machine**: Existing

**Total Infrastructure: $0**

### 6.3 Cost Optimization Strategies

1. **Cache frequent queries** - reduce API calls
2. **Use local embeddings** - eliminate embedding costs
3. **Implement conversation summarization** - reduce context length
4. **Rate limiting** - prevent cost spikes
5. **Monitor usage** - set budget alerts

---

## 7. Performance Targets

### 7.1 Response Time Goals

| Metric | Target | Acceptable | Critical |
|--------|--------|------------|----------|
| First token | <500ms | <1s | <2s |
| Streaming rate | >50 tokens/s | >20 tokens/s | >10 tokens/s |
| RAG retrieval | <200ms | <500ms | <1s |
| File processing | <2s/page | <5s/page | <10s/page |
| Search query | <1s | <2s | <3s |

### 7.2 Accuracy Targets

- **RAG Retrieval**: >85% relevance (top-5)
- **File Extraction**: >95% accuracy for clean files
- **Tool Selection**: >90% correct tool choice

### 7.3 Scalability Targets

- **Concurrent Users**: 1-5 (personal use)
- **Document Capacity**: 10,000 documents
- **Database Size**: <10GB
- **Memory Usage**: <2GB RAM

---

## 8. Risk Assessment & Mitigation

### 8.1 Technical Risks

| Risk | Probability | Impact | Mitigation |
|------|------------|--------|------------|
| **OpenAI API downtime** | Medium | High | Implement retry logic, queue requests, show user-friendly errors |
| **Streaming connection drops** | Medium | Medium | Auto-reconnect, resume from last position |
| **File processing failures** | High | Medium | Fallback parsers, graceful degradation, clear error messages |
| **ChromaDB corruption** | Low | High | Regular backups, use stable version, backup before updates |
| **Memory leaks in Swift** | Low | Medium | Proper memory management, testing, profiling |
| **Rate limiting** | Medium | Medium | Implement backoff, queue management, user notifications |

### 8.2 Cost Risks

| Risk | Probability | Impact | Mitigation |
|------|------------|--------|------------|
| **Unexpected API costs** | Medium | Medium | Token counting, budget alerts, cost dashboard |
| **Model price changes** | Low | Medium | Monitor OpenAI pricing, have fallback models |

### 8.3 UX Risks

| Risk | Probability | Impact | Mitigation |
|------|------------|--------|------------|
| **Slow responses** | Medium | High | Optimize prompts, use faster model variant, cache |
| **Poor reasoning quality** | Low | Medium | Prompt engineering, user feedback collection |
| **Confusing UI** | Medium | Medium | User testing, iterative design, tooltips |

---

## 9. Testing Strategy

### 9.1 Unit Tests

**Backend:**
- File processor tests (each format)
- RAG retrieval tests
- Tool execution tests
- API endpoint tests

**Frontend:**
- ViewModel tests
- Networking layer tests
- UI component tests

### 9.2 Integration Tests

- End-to-end chat flow
- File upload â†’ processing â†’ RAG
- Multi-tool orchestration
- Streaming pipeline

### 9.3 Performance Tests

- Load testing (concurrent requests)
- Memory profiling
- Database query optimization
- Streaming latency

### 9.4 User Acceptance Testing

- Real-world scenarios
- File format coverage
- Error handling
- UI/UX feedback

---

## 10. Success Criteria

### 10.1 Minimum Viable Product (MVP)

âœ… **Core Features:**
- [x] Chat with streaming responses
- [x] File upload and processing (PDF, images, text)
- [x] RAG-based memory
- [x] Internet search
- [x] Reasoning display
- [x] Modern, responsive UI

âœ… **Performance:**
- First token < 1s
- Smooth streaming
- File processing < 5s/page

âœ… **Reliability:**
- Error handling for common failures
- Data persistence
- 95% uptime for local server

### 10.2 Feature Complete

All MVP features plus:
- Advanced file formats (Excel, PowerPoint)
- Conversation export
- Settings and preferences
- Cost tracking dashboard
- Advanced search filters

### 10.3 Production Ready

Feature complete plus:
- Comprehensive testing (>80% coverage)
- Complete documentation
- Performance optimization
- Security hardening
- Backup/restore functionality

---

## 11. Future Enhancements (Post-MVP)

### 11.1 Advanced Features

1. **Multi-modal capabilities**
   - Voice input/output
   - Image generation
   - Video processing

2. **Collaboration**
   - Share conversations
   - Multi-user support
   - Team knowledge bases

3. **Automation**
   - Scheduled tasks
   - Webhooks
   - API for external integrations

4. **Advanced RAG**
   - Graph-based knowledge representation
   - Temporal awareness
   - Multi-hop reasoning

5. **Platform Expansion**
   - iOS companion app
   - Web interface
   - Browser extension

### 11.2 Model Improvements

- Fine-tuned models for specific domains
- Mixture of experts approach
- Local model fallback (Llama, Mistral)

---

## 12. Development Environment Setup

### 12.1 Prerequisites

**System Requirements:**
- macOS 13.0+ (for Swift 6)
- Python 3.11+
- 8GB RAM minimum (16GB recommended)
- 20GB free disk space
- Xcode 15.0+

**Accounts:**
- OpenAI API account with GPT-5-nano access
- GitHub account (for version control)

### 12.2 Backend Setup

```bash
# Clone repository
git clone <repo-url>
cd jarvis/backend

# Create virtual environment
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Create .env file
cat > .env << EOF
OPENAI_API_KEY=your_api_key_here
CHROMA_DB_PATH=./chroma_db
ENVIRONMENT=development
LOG_LEVEL=INFO
EOF

# Run server
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

### 12.3 Frontend Setup

```bash
# Open Xcode project
cd jarvis/frontend
open JarvisAI.xcodeproj

# Update API endpoint in Config.swift
# Configure signing & capabilities
# Build and run (âŒ˜R)
```

### 12.4 Project Structure

```
jarvis/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                 # FastAPI app entry
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â”œâ”€â”€ chat.py         # Chat endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ files.py        # File upload endpoints
â”‚   â”‚   â”‚   â””â”€â”€ health.py       # Health checks
â”‚   â”‚   â””â”€â”€ models/
â”‚   â”‚       â”œâ”€â”€ chat.py         # Pydantic models
â”‚   â”‚       â””â”€â”€ files.py
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ config.py           # Configuration
â”‚   â”‚   â”œâ”€â”€ openai_client.py   # OpenAI wrapper
â”‚   â”‚   â””â”€â”€ chroma_client.py   # ChromaDB wrapper
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ graph.py           # LangGraph definition
â”‚   â”‚   â”œâ”€â”€ tools.py           # Tool implementations
â”‚   â”‚   â””â”€â”€ state.py           # Agent state
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ file_processor/
â”‚   â”‚   â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   â”‚   â”œâ”€â”€ pdf.py
â”‚   â”‚   â”‚   â”œâ”€â”€ image.py
â”‚   â”‚   â”‚   â””â”€â”€ document.py
â”‚   â”‚   â”œâ”€â”€ rag_service.py
â”‚   â”‚   â””â”€â”€ search_service.py
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ logging.py
â”‚   â”‚   â””â”€â”€ helpers.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ .env.example
â”‚   â””â”€â”€ tests/
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ JarvisAI/
â”‚   â”‚   â”œâ”€â”€ JarvisAIApp.swift      # App entry point
â”‚   â”‚   â”œâ”€â”€ Views/
â”‚   â”‚   â”‚   â”œâ”€â”€ ContentView.swift
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatView.swift
â”‚   â”‚   â”‚   â”œâ”€â”€ MessageBubble.swift
â”‚   â”‚   â”‚   â”œâ”€â”€ ReasoningDropdown.swift
â”‚   â”‚   â”‚   â””â”€â”€ FileUploadView.swift
â”‚   â”‚   â”œâ”€â”€ ViewModels/
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatViewModel.swift
â”‚   â”‚   â”‚   â””â”€â”€ FileViewModel.swift
â”‚   â”‚   â”œâ”€â”€ Services/
â”‚   â”‚   â”‚   â”œâ”€â”€ APIService.swift
â”‚   â”‚   â”‚   â””â”€â”€ StreamingService.swift
â”‚   â”‚   â”œâ”€â”€ Models/
â”‚   â”‚   â”‚   â”œâ”€â”€ Message.swift
â”‚   â”‚   â”‚   â””â”€â”€ FileUpload.swift
â”‚   â”‚   â””â”€â”€ Utils/
â”‚   â”‚       â”œâ”€â”€ Config.swift
â”‚   â”‚       â””â”€â”€ Extensions.swift
â”‚   â””â”€â”€ JarvisAITests/
â”‚
â”œâ”€â”€ Docs/
â”‚   â”œâ”€â”€ API.md
â”‚   â”œâ”€â”€ SETUP.md
â”‚   â””â”€â”€ USER_GUIDE.md
â”‚
â””â”€â”€ README.md
```

---

## 13. Monitoring & Observability

### 13.1 Logging Strategy

**Log Levels:**
- DEBUG: Development details
- INFO: Normal operations
- WARNING: Potential issues
- ERROR: Failures requiring attention
- CRITICAL: System-wide failures

**What to Log:**
- API requests/responses
- Tool executions
- File processing events
- Errors and exceptions
- Performance metrics
- Cost tracking

### 13.2 Metrics to Track

**Performance:**
- Response times (p50, p95, p99)
- Streaming latency
- Database query times
- File processing speed

**Usage:**
- Messages per day
- Files uploaded
- RAG queries
- Search queries
- Tokens consumed

**Costs:**
- API costs by endpoint
- Total daily/monthly spend
- Cost per conversation

### 13.3 Tools

- Python `logging` module
- Custom metrics collector
- Simple dashboard (Streamlit or FastAPI HTML)
- Cost tracker in database

---

## 14. Security Considerations

### 14.1 API Security

- Store API keys in `.env` (never commit)
- Use environment variables
- Implement rate limiting
- Add request validation
- Sanitize file uploads

### 14.2 Data Privacy

- Local-first architecture (ChromaDB local)
- No data sent to third parties (except OpenAI)
- Clear data retention policy
- Option to delete conversations
- Secure file storage

### 14.3 File Upload Security

- File size limits (10MB default)
- File type validation
- Virus scanning (optional: ClamAV)
- Sandboxed processing
- Automatic cleanup of temp files

---

## 15. Conclusion & Next Steps

### 15.1 Assessment Summary

âœ… **This project is fully achievable** with the proposed technology stack. All components are mature, well-documented, and proven in production environments.

**Key Strengths:**
- GPT-5-nano provides excellent performance for an AI assistant
- LangGraph offers robust orchestration capabilities
- Swift6/SwiftUI ensures a native, high-quality macOS experience
- Local ChromaDB keeps data private and costs low
- FastAPI enables high-performance backend with minimal overhead

**Realistic Timeline:** 15-18 weeks for full implementation

**Estimated Cost:** $5-20/month for moderate usage (mostly OpenAI API)

### 15.2 Recommendations

**Start with MVP Focus:**
1. Build core chat functionality first (Phases 1-3)
2. Add file processing incrementally (Phase 4)
3. Implement RAG for memory (Phase 5)
4. Add search and polish (Phases 6-8)

**Critical Success Factors:**
- Keep prompts optimized for GPT-5-nano
- Test file processing with diverse real-world files
- Monitor costs from day one
- Prioritize streaming performance
- Gather user feedback early

**Don't Over-Engineer:**
- Start with simple implementations
- Optimize only when metrics show need
- Avoid premature abstractions
- Focus on core use cases first

### 15.3 Immediate Action Items

**Week 1 Actions:**
1. Set up development environment
2. Get OpenAI API access for GPT-5-nano
3. Create project repositories
4. Initialize FastAPI backend
5. Create Swift/SwiftUI project
6. Implement basic hello-world integration

**First Month Goals:**
- Working chat interface with streaming
- Basic file upload capability
- Foundation for LangGraph integration

---

## 16. Appendix

### 16.1 Glossary

- **RAG**: Retrieval-Augmented Generation
- **SSE**: Server-Sent Events
- **LLM**: Large Language Model
- **Embedding**: Vector representation of text
- **Streaming**: Real-time token-by-token response delivery
- **Tool Calling**: LLM's ability to invoke external functions

### 16.2 References

- [OpenAI GPT-5 Documentation](https://platform.openai.com/docs/models/gpt-5)
- [LangGraph Documentation](https://docs.langchain.com/oss/python/langgraph/)
- [ChromaDB Documentation](https://docs.trychroma.com/)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Swift Documentation](https://www.swift.org/documentation/)
- [SwiftUI Tutorials](https://developer.apple.com/tutorials/swiftui)

### 16.3 Contact & Support

- **Project Lead**: [Your Name]
- **Repository**: [GitHub URL]
- **Documentation**: [Docs URL]
- **Issue Tracker**: [Issues URL]

---

**Document Version:** 1.0  
**Last Updated:** December 27, 2025  
**Status:** Ready for Implementation  
**Approval:** Pending Review
